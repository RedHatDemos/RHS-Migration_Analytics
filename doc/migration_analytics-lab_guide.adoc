:scrollbar:
:data-uri:
:toc2:
:imagesdir: images

== Migration Analytics 0.1 beta - Lab Guide

:numbered:

== Overview

This Lab is built to help better understand the status of a running environment in order to assess, plan and execute a migration from a proprietary environment to an open source one. In order to do so, there are two tools built to help obtain and process data, initially focused on the Virtualization layer, but working to introspect the Operating System as well as the Applications. 
[NOTE] 
If you are interested in migrating applications, please check the link:https://developers.redhat.com/products/rhamt/overview[Red Hat Application Migration Toolkit]

The Lab Environment uses, to obtain data, the *Workload Examination Toolkit* (a.k.a. WET) which is a Migration Analytics plugin within Red Hat CloudForms. This toolkit help obtain the data, and download it as a single file to it can be reviewed, and then uploaded to be analyzed.

In order to analyze data, we will use the *Workload Analysis Tool* (a.k.a. WAT), which is an application running as SaaS on cloud.redhat.com. This tool will help us obtain the following reports to better understand the cost, risk and effort required to perform the migration:
* Initial Savings Estimation
* Workload Migration Summary
* Workload Migration Inventory

.Goal
* the goal of this lab is to obtain a set of data from a running environment, review it, upload it to be analyzed, and understand the benefits of the outcome provided in order to better assess and drive a migration.

== Overview

The environment to be used for this lab provides a running VMware vSphere environment with different workloads on it, and a deployed and configured Red Hat CloudForms instancei, with the Migration Analytics plugin configured to obtain data from it.

In this environment the following configuration steps are already done:

* Enabled Migration Analytics plugin in CloudForms
* Added the `vSphere` virtualization provider in CloudForms
* Provide credentials for virtualization providers and hosts in CloudForms
* Configured Smart State Analysis in CloudForms
* Configured Ansible, an ansible hosts file, in `workstation` andi, exchanged ssh keys (`/root/.ssh/id_rsa`) with all running machines.

The password to access all services is available link:https://mojo.redhat.com/docs/DOC-1174612-accessing-red-hat-solutions-lab-in-rhpds[here]

Required versions of products used:

[cols="1,1",options="header"]
|=======
|Product |Version
|CloudForms |5.0.0+ 
|VMware vSphere |5.5+ (6.7 used)
|=======

The Migration Analytics analysis tool (WAT) is running as an application on the OpenShift instances that poser cloud.redhat.com. The tool uses Red Hat Decision Manager, Red Hat AMQ, Red Hat Fuse and other opensource tools to run. for more information please check link:https://project-xavier.io[project-xavier.io].

== Requirements to access and perform this lab

=== Base requirements

* A computer with access to the Internet :-)
* SSH client
* Firefox, or Chromium / Chrome
+
[NOTE]
Grammarly plugin for Chrome causes problems when managing CloudForms. Please deactivate it while doing this lab.

=== Obtaining or enabling access credentials

. First time login?, forgot login or password? Go to https://www.opentlc.com/account 

. Note, your username should NOT have an *@* in it. 

. Red Hat Partners can also request access to the Red Hat Product Demo System (link:https://rhpds.redhat.com[RHPDS]) by sending an email to open-program@redhat.com. 

. Passwords to the services are referred as `<to_be_provided>`. The credentials to access all services are available link:https://mojo.redhat.com/docs/DOC-1174612-accessing-red-hat-solutions-lab-in-rhpds[here]. If you can't access it please contact GPTE or the link:https://mojo.redhat.com/community/marketing/vertical-marketing/horizontal-solutions/people[Horizontal Solutions Team].

== Environment

A full new migration environment is deployed on every request. To make the environment unique a 4 character identifier is assigned to it (i.e. `1e37`), this identifier is referred in this documentation as *YOUR-GUID*.  

The migration environment consists of the following systems:

image::blueprint.png[Blueprint]

[cols="1,1,1,2",options="header"]
|=======
| Hostname | Internal IP | External name | Description
|`workstation.example.com` |`192.168.0.10` | workstation-<YOUR-GUID>.rhpds.opentlc.com |Jump host and Ansible host
|`storage.example.com` |`192.168.0.254` | workstation-<YOUR-GUID>.rhpds.opentlc.com | NFS server
|`cf.example.com` |`192.168.0.100` |  cf-<YOUR-GUID>.rhpds.opentlc.com |CloudForms server
|`vcenter.example.com` |`192.168.0.50` | vcenter-<YOUR-GUID>.rhpds.opentlc.com |VMware vCenter server
|`esx1.example.com` |`192.168.0.51` | N/A |ESXi hypervisor
|`esx2.example.com` |`192.168.0.52` | N/A |ESXi hypervisor
|=======

The architecture of the deployment can be depicted as it follows:

image::architecture_diagram.png[Architecture Diagram]

* Networks
Networks used in the environment

[cols="1,1,2",options="header"]
|=======
| Network Name | IP range | Description
| `Admin` | `192.168.x.x/16` | General administration and storage network.
| `Service` | `10.10.0.x/24` | Internal network for the app to connect LB to EAP and to DB. 
| `Servicer-DMZ` | `10.9.0.x/24` | External DMZ network to publish the app. Also access to the user API for OSP and Horizon (provider network)
| `OSP Provisioning` | `10.100.0.x/24` | OpenStack provisioning network (includes Director and PXE), as well as access to the Admin API endpoint and control plane.  
|=======

* Virtual Machines 
This deployment of the migration environment includes the following VMs provisioned in the vSphere environment in order to be migrated:

[cols="1,1,2",options="header"]
|=======
| Name | IPs | Description
| `jboss0.example.com` | 10.10.0.110 | Red Hat Enterprise Linux 7 host running JBoss EAP, connected to the `Service` network for ticket-monster.
| `jboss1.example.com` | 10.10.0.111 | Red Hat Enterprise Linux 7 host running JBoss EAP, connected to the `Service` network for ticket-monster.
| `lb.example.com` | 10.10.0.100 , 10.9.0.100 | Red Hat Enterprise Linux 7 host running JBoss Core Service Apache HTTP server configured with mod_cluster to proxy traffic to `jboss0` and `jboss1`, connected to the `Service` and `Servicer-DMZ` networks for ticket-monster.
| `db.example.com` | 10.10.0.120 | Red Hat Enterprise Linux 7 host running PostgreSQL providing service to `jboss0` and `jboss1` through the `Service` network for ticket-monster.
| `hana.example.com` | 10.10.0.150 | Red Hat Enterprise Linux 7 HANA Express through the `Service` network.
| `tomcat.example.com` | 10.10.0.180 | CentOS 7 host running Apache Tomcat 8 server through the `Service` network.
|=======

* An external service is configured as https://app-<YOUR-GUID>.rhpds.opentlc.com pointing to the Load Balancer to make the Ticket Monster app accessible.

== Getting Started

. Once the system is running, use SSH to access your demo server using your OPENTLC login name and private SSH key.

* Using a Unix/Linux system:
+
----
$ ssh -i /path/to/private_key <YOUR-OpenTLC-USERNAME-redhat.com>@workstation-<YOUR-GUID>.rhpds.opentlc.com
----

* Example for user 'batman' and GUID '1e37', using the default ssh private key:
+
----
$ ssh -i ~/.ssh/id_rsa batman-redhat.com@workstation-1e37.rhpds.opentlc.com
----

. Become `root` using the provided password:
+
----
$ sudo -i
----

. Check the status of the whole environment, from the `workstation`, using ansible:
+
----
# ansible all -m ping
----
+
This command establishes a connection to all the machines in the environment (except ESXi servers). 
In case the machines are up an running a success message, per each, will show up. 
This is an example of a success message for the VM `cf.example.com`:
+
----
cf.example.com | SUCCESS => {
    "changed": false, 
    "ping": "pong"
}
----
+ 
To check the infrastructure machines the following command can be also used:
+
----
# ansible infra -m ping
----
There are 4 VMs in the vCenter environment hosting an app with JBoss Core Services' Apache HTTP + modcluster as loadbalancer, two JBoss EAP 7 in domain mode, and a Postgresql database.
To check only if these ones are running, you may use the following command:
+
----
# ansible app -m ping
----
+ 
[NOTE]
As this environment is quite big, and it is generated and powered up for you in a cloud environment, some resources may suffer from issues or delays depending on the status of the cloud. You may need to manually start up or reboot some of them. Please review everything is running before proceeding forward.

. Establish an SSH connection to the CloudForms server and monitor `automation.log`:
+
----
# ssh cf.example.com
# tail -f /var/www/miq/vmdb/log/automation.log
----
+
[TIP]
The log entries are very long, so it helps if you stretch this window as wide as possible.
+
[NOTE]
The log entries can be also seen in the CloudForms web UI in *Automation -> Automate -> Log*.

. Verify that the Ticket Monster app is running:

* Point your browser to https://app-<YOUR-GUID>.rhpds.opentlc.com and check it is running:
+
image::app-ticketmonster-running.png[Ticket Monster app running]
[NOTE]
You must accept all of the self-signed SSL certificates.
+
image::ssl_cert_warning.png[SSL Cert Warning]
+
If the ticketmonster app is not running, you may run the following command in `workstation`:
+
----
# start_vms
----

. Prepare to manage the environment. From a web browser, open each of the URLs below in its own window or tab, using these credentials (except when noted):

* *Username*: `admin`
* *Password*: `<to_be_provided>`
+
[NOTE]
You must accept all of the self-signed SSL certificates.
+

